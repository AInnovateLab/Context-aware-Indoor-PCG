{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyvista as pv\n",
    "import accelerate\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict as edict\n",
    "from termcolor import colored\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local jupyter\n",
    "jupyter_backend = \"trame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote jupyter\n",
    "def is_vscode() -> bool:\n",
    "    for var in os.environ:\n",
    "        if var == \"VSCODE_CWD\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "if is_vscode():\n",
    "    print(colored(\"Vscode jupyter DOESN'T support pyvista interative mode\", \"yellow\", force_color=True))\n",
    "    jupyter_backend = \"static\"\n",
    "else:\n",
    "    jupyter_backend = \"trame\"\n",
    "\n",
    "# set this if on remote jupyter\n",
    "# for headless linux users\n",
    "os.environ[\"DISPLAY\"] = \":99.0\"\n",
    "os.environ[\"PYVISTA_OFF_SCREEN\"] = \"true\"\n",
    "# NOTE: vscode remote jupyter does not work with pyvista\n",
    "if not is_vscode():\n",
    "    pv.global_theme.trame.server_proxy_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = accelerate.Accelerator()\n",
    "device = accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write and Load point cloud functions (option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def write_ply(points, save_path):\n",
    "    \"\"\"\n",
    "    points: numpy array in shape (N, 6) or (N, 7)\n",
    "    save_name: str end with \".ply\"\n",
    "    \"\"\"\n",
    "    assert points.shape[1] == 6 or points.shape[1] == 7, \"points.shape[1] should be 6 or 7\"\n",
    "    save_path = str(save_path)\n",
    "    assert save_path.endswith(\".ply\"), \"save_name should end with '.ply'\"\n",
    "    points = [\n",
    "        (points[i, 0], points[i, 1], points[i, 2], points[i, 3], points[i, 4], points[i, 5])\n",
    "        for i in range(points.shape[0])\n",
    "    ]\n",
    "    vertex = np.array(\n",
    "        points,\n",
    "        dtype=[\n",
    "            (\"x\", \"f4\"),\n",
    "            (\"y\", \"f4\"),\n",
    "            (\"z\", \"f4\"),\n",
    "            (\"red\", \"f4\"),\n",
    "            (\"green\", \"f4\"),\n",
    "            (\"blue\", \"f4\"),\n",
    "        ],\n",
    "    )\n",
    "    data = PlyElement.describe(vertex, \"vertex\", comments=[\"vertices\"])\n",
    "    PlyData([data]).write(save_path)\n",
    "\n",
    "def read_ply(save_path):\n",
    "    filename = save_path\n",
    "    with open(filename, 'rb') as f:\n",
    "        plydata = PlyData.read(f)\n",
    "        num_verts = plydata['vertex'].count\n",
    "        vertices = np.zeros(shape=[num_verts, 6], dtype=np.float32)\n",
    "        vertices[:,0] = plydata['vertex'].data['x']\n",
    "        vertices[:,1] = plydata['vertex'].data['y']\n",
    "        vertices[:,2] = plydata['vertex'].data['z']\n",
    "        vertices[:,3] = plydata['vertex'].data['red']\n",
    "        vertices[:,4] = plydata['vertex'].data['green']\n",
    "        vertices[:,5] = plydata['vertex'].data['blue']\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing args\n",
    "PROJECT_TOP_DIR = \"your/project/dir\"\n",
    "PROJECT_DIR = osp.join(PROJECT_TOP_DIR, \"dir/of/model\")\n",
    "CHECKPOINT_DIR = osp.join(\n",
    "    PROJECT_DIR,\n",
    "    \"checkpoints/folder/name\",\n",
    ")\n",
    "with open(osp.join(PROJECT_DIR, \"config.json.txt\"), \"r\") as f:\n",
    "    args = edict(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.referit3d.in_out.neural_net_oriented import (\n",
    "    compute_auxiliary_data,\n",
    "    load_referential_data,\n",
    "    load_scan_related_data,\n",
    "    trim_scans_per_referit3d_data_,\n",
    ")\n",
    "# load data\n",
    "SCANNET_PKL_FILE = \"../../datasets/scannet/instruct/global_small.pkl\"\n",
    "REFERIT_CSV_FILE = \"../../datasets/nr3d/nr3d_generative_20230825_final.csv\"\n",
    "all_scans_in_dict, scans_split, class_to_idx = load_scan_related_data(SCANNET_PKL_FILE)\n",
    "referit_data = load_referential_data(args, args.referit3D_file, scans_split)\n",
    "# Prepare data & compute auxiliary meta-information.\n",
    "all_scans_in_dict = trim_scans_per_referit3d_data_(referit_data, all_scans_in_dict)\n",
    "mean_rgb = compute_auxiliary_data(referit_data, all_scans_in_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# prepare tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_pretrain_path)\n",
    "# Prepare the Listener\n",
    "n_classes = len(class_to_idx) - 1  # -1 to ignore the <pad> class\n",
    "pad_idx = class_to_idx[\"pad\"]\n",
    "# Object-type classification\n",
    "class_name_list = list(class_to_idx.keys())\n",
    "\n",
    "class_name_tokens = tokenizer(class_name_list, return_tensors=\"pt\", padding=True)\n",
    "class_name_tokens = class_name_tokens.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.referit3d.datasets import make_data_loaders\n",
    "data_loaders = make_data_loaders(\n",
    "    args=args,\n",
    "    accelerator=accelerator,\n",
    "    referit_data=referit_data,\n",
    "    class_to_idx=class_to_idx,\n",
    "    scans=all_scans_in_dict,\n",
    "    mean_rgb=mean_rgb,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_utils import move_batch_to_device_\n",
    "# get random data\n",
    "test_dataset = data_loaders[\"test\"].dataset\n",
    "rand_idx = np.random.randint(0, len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data = test_dataset[rand_idx]\n",
    "print(f\"Original text: {rand_data['text']}\")\n",
    "rand_data_scan, rand_data_target_objs = test_dataset.get_reference_data(rand_idx)[:2]\n",
    "rand_data_3d_objs = rand_data_scan.three_d_objects.copy()\n",
    "rand_data_3d_objs.remove(rand_data_target_objs)\n",
    "# rand_data[\"text\"] = \"Create a light color chair in the center of the backpack and the door.\"\n",
    "# rand_data[\"tokens\"] = test_dataset.tokenizer(rand_data[\"text\"], max_length=test_dataset.max_seq_len, truncation=True, padding=False)\n",
    "collate_fn = data_loaders[\"test\"].collate_fn\n",
    "# get batch\n",
    "batch = collate_fn([rand_data])\n",
    "batch = move_batch_to_device_(batch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load models with checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.referit3d_model.referit3d_net import ReferIt3DNet_transformer\n",
    "from models.point_e_model.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from models.point_e_model.diffusion.sampler import PointCloudSampler\n",
    "from models.point_e_model.models.configs import MODEL_CONFIGS, model_from_config\n",
    "\n",
    "# referit3d model\n",
    "mvt3dvg = ReferIt3DNet_transformer(args, n_classes, class_name_tokens, ignore_index=pad_idx)\n",
    "# point-e model\n",
    "point_e_config = MODEL_CONFIGS[args.point_e_model]\n",
    "point_e_config[\"cache_dir\"] = osp.join(PROJECT_TOP_DIR, \"cache\", \"point_e_model\")\n",
    "point_e_config[\"n_ctx\"] = args.points_per_object\n",
    "point_e = model_from_config(point_e_config, device)\n",
    "point_e_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[args.point_e_model])\n",
    "# move models to gpu\n",
    "mvt3dvg = mvt3dvg.to(device).eval()\n",
    "point_e = point_e.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and checkpoints\n",
    "if args.mode == \"train\":\n",
    "    mvt3dvg = torch.compile(mvt3dvg)\n",
    "mvt3dvg, point_e = accelerator.prepare(mvt3dvg, point_e)\n",
    "accelerator.load_state(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.point_e_model.diffusion.sampler import PointCloudSampler\n",
    "\n",
    "aux_channels = [\"R\", \"G\", \"B\"]\n",
    "sampler = PointCloudSampler(\n",
    "    device=device,\n",
    "    models=[point_e],\n",
    "    diffusions=[point_e_diffusion],\n",
    "    num_points=[args.points_per_object],\n",
    "    aux_channels=aux_channels,\n",
    "    guidance_scale=[3.0],\n",
    "    use_karras=[True],\n",
    "    karras_steps=[64],\n",
    "    sigma_min=[1e-3],\n",
    "    sigma_max=[120],\n",
    "    s_churn=[3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ctx_embeds, LOSS, CLASS_LOGITS, LANG_LOGITS, LOCATE_PREDS, pred_xyz = mvt3dvg(batch)\n",
    "\n",
    "    prompts = batch[\"text\"]\n",
    "    # stack twice for guided scale\n",
    "    ctx_embeds = torch.cat((ctx_embeds, ctx_embeds), dim=0)\n",
    "    samples_it = sampler.sample_batch_progressive(\n",
    "        batch_size=len(prompts),\n",
    "        ctx_embeds=ctx_embeds,\n",
    "        model_kwargs=dict(texts=prompts),\n",
    "        accelerator=accelerator,\n",
    "    )\n",
    "    # get the last timestep prediction\n",
    "    for last_pcs in samples_it:\n",
    "        pass\n",
    "    last_pcs = last_pcs.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis Norm model model's postprocessing for generated point cloud ###\n",
    "**Only for axis norm model**, if your model did not apply `--axis-norm` option, please skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For axis_norm model\n",
    "TOPK = 10\n",
    "pred_xy, pred_z, pred_radius = pred_xyz\n",
    "pred_xy_topk_bins = pred_xy.topk(TOPK, dim=-1)[1]  # (B, 5)\n",
    "# pred_z_topk_bins = pred_z.topk(5, dim=-1)[1]  # (B, 5)\n",
    "pred_z_topk_bins = pred_z.argmax(dim=-1, keepdim=True).repeat(1, TOPK)  # (B, 5)\n",
    "pred_x_topk_bins = pred_xy_topk_bins % args.axis_norm_bins  # (B, 5)\n",
    "pred_y_topk_bins = pred_xy_topk_bins // args.axis_norm_bins  # (B, 5)\n",
    "pred_bins = torch.stack(\n",
    "    (pred_x_topk_bins, pred_y_topk_bins, pred_z_topk_bins), dim=-1\n",
    ")  # (B, 5, 3)\n",
    "pred_bins = (pred_bins.float() + 0.5) / args.axis_norm_bins  # (B, 5, 3)\n",
    "(\n",
    "    min_box_center_axis_norm,  # (B, 3)\n",
    "    max_box_center_axis_norm,  # (B, 3)\n",
    ") = (\n",
    "    batch[\"min_box_center_before_axis_norm\"],\n",
    "    batch[\"max_box_center_before_axis_norm\"],\n",
    ")  # all range from [-1, 1]\n",
    "pred_topk_xyz = (\n",
    "    min_box_center_axis_norm[:, None]\n",
    "    + (max_box_center_axis_norm - min_box_center_axis_norm)[:, None] * pred_bins\n",
    ")  # (B, 5, 3)\n",
    "pred_radius = pred_radius.unsqueeze(-1).permute(0, 2, 1).repeat(1, 5, 1)  # (B, 5, 1)\n",
    "# pred_topk_xyz = torch.cat([pred_topk_xyz, pred_radius], dim=-1)  # (B, 5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axis-norm provides the topk axis for generated point cloud, you may choose by modifying the `object_idx` in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose this or the next block\n",
    "# Choose which object position to visualize\n",
    "# The object_idx should between 0 - 4\n",
    "object_idx = 0\n",
    "\n",
    "vis_pc = last_pcs.squeeze(0) # (P, 6)\n",
    "\n",
    "pos = vis_pc[:, :3]\n",
    "aux = vis_pc[:, 3:]\n",
    "\n",
    "pred_box_center, pred_box_max_dist = pred_topk_xyz[:, object_idx, :], pred_radius[:, 0, :]\n",
    "\n",
    "# Process the generated point cloud\n",
    "coords = pos * pred_box_max_dist + pred_box_center\n",
    "colors = aux.clamp(0, 255).round()  # (P, 3 or 4)\n",
    "vis_pc = torch.cat((coords, colors), dim=-1)  # (P, 6)\n",
    "vis_pc = vis_pc.unsqueeze(0) # (1, P, 6)\n",
    "vis_pc = vis_pc.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### None-axis Norm model's postprocessing for generated point cloud ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace last_pcs with the real point cloud\n",
    "vis_pc = last_pcs.squeeze(0) # (P, 6)\n",
    "\n",
    "pos = vis_pc[:, :3]\n",
    "aux = vis_pc[:, 3:]\n",
    "\n",
    "pred_box_center, pred_box_max_dist = LOCATE_PREDS[0, :3], LOCATE_PREDS[0, 3]\n",
    "\n",
    "# Process the generated point cloud\n",
    "coords = pos * pred_box_max_dist + pred_box_center\n",
    "colors = aux.clamp(0, 255).round()  # (P, 3 or 4)\n",
    "vis_pc = torch.cat((coords, colors), dim=-1)  # (P, 6)\n",
    "vis_pc = vis_pc.unsqueeze(0) # (1, P, 6)\n",
    "vis_pc = vis_pc.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is scene id and instructed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The scene id is: {batch['scan_id']}\")\n",
    "print(f\"The instructed text is: {batch['text']}\") \n",
    "print(f\"The number of padding objects is: {batch['ctx_key_padding_mask'].sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pyvista point cloud object\n",
    "plotter = pv.Plotter()\n",
    "plotter.window_size = (800, 600)\n",
    "if saved_cpos:\n",
    "    plotter.camera_position = saved_cpos\n",
    "\n",
    "# add generated objects\n",
    "# obj = vis_pc[0]\n",
    "# mesh = pv.PolyData(obj[:, :3]).delaunay_3d(alpha=0.005)\n",
    "# color = obj[:, 3:6].astype(np.uint8)\n",
    "# bound = mesh.bounds\n",
    "# plotter.add_box_widget(callback=None, bounds=bound, factor=1.25, outline_translation=False, rotation_enabled=False, color=\"red\")\n",
    "# plotter.add_mesh(mesh, scalars=color, rgb=True, preference='point')\n",
    "\n",
    "# add reference objects\n",
    "mesh = pv.PolyData(rand_data_target_objs.pc).delaunay_3d(alpha=1e-3)\n",
    "color = (rand_data_target_objs.color * 255).astype(np.uint8)\n",
    "bound = mesh.bounds\n",
    "plotter.add_box_widget(callback=None, bounds=bound, factor=1.25, outline_translation=False, rotation_enabled=False, color=\"blue\")\n",
    "plotter.add_mesh(mesh, scalars=color, rgb=True, preference='point')\n",
    "\n",
    "# add context\n",
    "for obj in rand_data_3d_objs:\n",
    "    mesh = pv.PolyData(obj.pc).delaunay_3d(alpha=1e-3)\n",
    "    color = (obj.color * 255).astype(np.uint8)\n",
    "    plotter.add_mesh(mesh, scalars=color, rgb=True, preference='point')\n",
    "\n",
    "plotter.show(jupyter_backend=jupyter_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_cpos = plotter.camera_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter.save_graphic(f\"{batch['stimulus_id'][0]}_wo.svg\")\n",
    "plotter.save_graphic(f\"{batch['stimulus_id'][0]}_ref.svg\")\n",
    "# plotter.save_graphic(f\"{batch['stimulus_id'][0]}_{object_idx}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_cpos = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Automatically select topk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for object_idx in tqdm(range(TOPK)):\n",
    "    # generate\n",
    "    with torch.no_grad():\n",
    "        ctx_embeds, LOSS, CLASS_LOGITS, LANG_LOGITS, LOCATE_PREDS, pred_xyz = mvt3dvg(batch)\n",
    "    \n",
    "        prompts = batch[\"text\"]\n",
    "        # stack twice for guided scale\n",
    "        ctx_embeds = torch.cat((ctx_embeds, ctx_embeds), dim=0)\n",
    "        samples_it = sampler.sample_batch_progressive(\n",
    "            batch_size=len(prompts),\n",
    "            ctx_embeds=ctx_embeds,\n",
    "            model_kwargs=dict(texts=prompts),\n",
    "            accelerator=accelerator,\n",
    "        )\n",
    "        # get the last timestep prediction\n",
    "        for last_pcs in samples_it:\n",
    "            pass\n",
    "        last_pcs = last_pcs.permute(0, 2, 1)\n",
    "    # locate\n",
    "    vis_pc = last_pcs.squeeze(0) # (P, 6)\n",
    "    \n",
    "    pos = vis_pc[:, :3]\n",
    "    aux = vis_pc[:, 3:]\n",
    "    \n",
    "    pred_box_center, pred_box_max_dist = pred_topk_xyz[:, object_idx, :], pred_radius[:, 0, :]\n",
    "\n",
    "    coords = pos * pred_box_max_dist + pred_box_center\n",
    "    colors = aux.clamp(0, 255).round()  # (P, 3 or 4)\n",
    "    vis_pc = torch.cat((coords, colors), dim=-1)  # (P, 6)\n",
    "    vis_pc = vis_pc.unsqueeze(0) # (1, P, 6)\n",
    "    vis_pc = vis_pc.cpu().numpy()\n",
    "    # Create a pyvista point cloud object\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.window_size = (800, 600)\n",
    "    if saved_cpos:\n",
    "        plotter.camera_position = saved_cpos\n",
    "    \n",
    "    # add generated objects\n",
    "    obj = vis_pc[0]\n",
    "    mesh = pv.PolyData(obj[:, :3]).delaunay_3d(alpha=0.005)\n",
    "    color = obj[:, 3:6].astype(np.uint8)\n",
    "    bound = mesh.bounds\n",
    "    plotter.add_box_widget(callback=None, bounds=bound, factor=1.25, outline_translation=False, rotation_enabled=False, color=\"red\")\n",
    "    plotter.add_mesh(mesh, scalars=color, rgb=True, preference='point')\n",
    "    \n",
    "    # add context\n",
    "    for obj in rand_data_3d_objs:\n",
    "        mesh = pv.PolyData(obj.pc).delaunay_3d(alpha=1e-3)\n",
    "        color = (obj.color * 255).astype(np.uint8)\n",
    "        plotter.add_mesh(mesh, scalars=color, rgb=True, preference='point')\n",
    "\n",
    "    # save\n",
    "    plotter.save_graphic(f\"{batch['stimulus_id'][0]}_{object_idx}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The scene id is: {batch['scan_id']}\")\n",
    "print(f\"The instructed text is: {batch['text']}\") \n",
    "print(f\"The number of padding objects is: {batch['ctx_key_padding_mask'].sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "with torch.no_grad():\n",
    "    ctx_embeds, LOSS, CLASS_LOGITS, LANG_LOGITS, LOCATE_PREDS, pred_xyz = mvt3dvg(batch)\n",
    "\n",
    "    prompts = batch[\"text\"]\n",
    "    # stack twice for guided scale\n",
    "    ctx_embeds = torch.cat((ctx_embeds, ctx_embeds), dim=0)\n",
    "    samples_it = sampler.sample_batch_progressive(\n",
    "        batch_size=len(prompts),\n",
    "        ctx_embeds=ctx_embeds,\n",
    "        model_kwargs=dict(texts=prompts),\n",
    "        accelerator=accelerator,\n",
    "    )\n",
    "    # get the last timestep prediction\n",
    "    for last_pcs in samples_it:\n",
    "        pass\n",
    "    last_pcs = last_pcs.permute(0, 2, 1)\n",
    "# Process the generated point cloud\n",
    "vis_pc = last_pcs.squeeze(0) # (P, 6)\n",
    "pos = vis_pc[:, :3]\n",
    "aux = vis_pc[:, 3:]\n",
    "coords = pos\n",
    "colors = aux.clamp(0, 255).round()  # (P, 3 or 4)\n",
    "vis_pc = torch.cat((coords, colors), dim=-1)  # (P, 6)\n",
    "vis_pc = vis_pc.unsqueeze(0) # (1, P, 6)\n",
    "vis_pc = vis_pc.cpu().numpy()\n",
    "\n",
    "# Create a pyvista point cloud object\n",
    "plotter = pv.Plotter()\n",
    "plotter.window_size = (800, 600)\n",
    "if saved_cpos:\n",
    "    plotter.camera_position = saved_cpos\n",
    "\n",
    "# add generated objects\n",
    "obj = vis_pc[0]\n",
    "mesh = pv.PolyData(obj[:, :3]).delaunay_3d(alpha=0.005)\n",
    "color = obj[:, 3:6].astype(np.uint8)\n",
    "bound = mesh.bounds\n",
    "plotter.add_mesh(mesh, scalars=color, rgb=True, preference='point')\n",
    "plotter.show(jupyter_backend=jupyter_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_cpos = plotter.camera_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.save_graphic(f\"{batch['stimulus_id'][0]}_2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_cpos = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
